Metadata-Version: 2.4
Name: laklab-mouseloader
Version: 0.1
Summary: LakLab MouseLoader: Package for loading and analyzing rodent visual behavior experiments with Neuropixels data, including histology registration, alignment tools, and RigBox Timeline/Block file parsers
Author-email: mbfl <micllynn@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/mbfl/laklab_mouseloader
Project-URL: Repository, https://github.com/mbfl/laklab_mouseloader
Keywords: neuropixels,electrophysiology,behavior,neuroscience,two-photon,imaging,histology,rigbox,mouse,laklab
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: numpy>=1.20.0
Requires-Dist: scipy>=1.7.0
Requires-Dist: matplotlib>=3.4.0
Requires-Dist: seaborn>=0.11.0
Requires-Dist: pandas>=1.3.0
Requires-Dist: scikit-learn>=1.0.0
Requires-Dist: statsmodels>=0.13.0
Requires-Dist: tifffile>=2021.0.0
Requires-Dist: zetapy>=1.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: black>=22.0.0; extra == "dev"
Requires-Dist: flake8>=4.0.0; extra == "dev"
Requires-Dist: mypy>=0.950; extra == "dev"

This package is designed to load complex rodent visual behavior experiments
(typically collected with RigBox) as well as simultaneous neural recordings
(Neuropixels or two-photon, 2p).

It includes tools to align behavior with both 2p and npix recordings,
perform analysis on both behavior and recording, and visualize
the results (ranging from simple daily behavioral checkers to more
sophisticated dimensionality-reduction visualizations)

It is written for use with LakLab style experiments.

## Installation

### Prerequisites
- Python 3.8 or higher
- conda or pip package manager

### Install from GitHub

1. **Clone the repository:**
```bash
git clone https://github.com/mbfl/laklab_mouseloader.git
cd laklab_mouseloader
```

2. **Install the package:**

For development (editable install, recommended):
```bash
pip install -e .
```

For standard installation:
```bash
pip install .
```

This will automatically install all required dependencies (numpy, scipy, matplotlib, pandas, scikit-learn, statsmodels, seaborn, tifffile, zetapy) and make command-line tools available.

3. **Verify installation:**
```python
import laklab_mouseloader as lml
print(lml.__file__)  # Should print package location
```

Or test the command-line tool:
```bash
beh-check --help
```

## Main usage

This package can load behavioral data files generated by **RigBox** (Block.mat and Timeline.mat files), either standalone or in combination with simultaneously acquired neural recordings from Neuropixels or two-photon imaging.

```python
import laklab_mouseloader as lml
```

### 1. Loading behavior data alone

For loading and parsing behavioral data from RigBox experiments without neural recordings:

```python
from laklab_mouseloader.beh import BehDataSimpleLoad, BlockParser, TimelineParser

# Simple behavior loading with stimulus parsing
beh = BehDataSimpleLoad('/path/to/animal/date/folder',
                        parse_stims=True,
                        parse_by='stimulusOrientation')

# Access stimulus information
stim_times = beh.stim.t_start
stim_orientations = beh._stimparser.ori

# Low-level parsing of Block and Timeline files
block = BlockParser('/path/to/Block.mat')
timeline = TimelineParser('/path/to/Timeline.mat')
```


### 2. Loading behavior data and simultaneous neuropixels recording (load_exp.py)

For experiments with Neuropixels recordings and simultaneous behavior:

```python
# Load dataset metadata
dset = lml.DSetObj(path_reportopto='path_to_dataset.csv')

# Load a specific experiment (includes behavior, ephys, and alignment)
exp = lml.ExpObj_ReportOpto(dset_obj=dset, dset_ind=5)
exp.plt_exp()  # visualizes experiment

# Access components
exp.beh      # Behavior data
exp.ephys    # Neuropixels data (spike times, clusters, histology)
exp.aligner  # Alignment between behavior and ephys clocks
```
![plt_exp_output](/plt_exp_out.jpg)

For ValuePFC experiments:
```python
exp = lml.ExpObj_ValuePFC(dset_obj=dset, dset_ind=5)
```

### 3. Loading behavior data and simultaneous two-photon (2p) recording (load_exp_twop.py)

For experiments with two-photon calcium imaging and simultaneous behavior:

```python
from laklab_mouseloader.load_exp_twop import TwoPRec

# Basic loading (auto-detects compiled .tif file)
rec = TwoPRec(enclosing_folder='/path/to/animal/date/',
              folder_beh='1',
              folder_img='TwoP/2025-06-17_t-001',
              ch_img=2)  # Channel 1 or 2

# Access components
rec.rec      # Raw .tif recording (memory-mapped, t x px_x x px_y)
rec.rec_t    # Timestamps for imaging frames (aligned to behavior clock)
rec.beh      # Behavior data (stim, rew, lick)
rec.neur     # Suite2p outputs (F, ops, stat, iscell) if available
rec.samp_rate  # Imaging sampling rate (Hz)
```

**Alignment modes for .tif recordings** (controlled by `rec_type` parameter):

1. **'trig_rew'** (default): Imaging triggered at first reward delivery
   - Simple time alignment: imaging start = first reward time
   - Use when imaging acquisition is triggered by behavior system

2. **'paqio'**: Manual acquisition with .paq synchronization file
   - Uses reward echoes from both .paq (imaging) and Timeline.mat (behavior)
   - Performs linear regression alignment between clocks
   - Use when imaging and behavior started independently

```python
# Example: paqio alignment mode
rec = TwoPRec(enclosing_folder='/path/to/animal/date/',
              folder_beh='1',
              folder_img='TwoP/2025-06-17_t-001',
              rec_type='paqio')  # Uses Aligner_ImgBeh for clock alignment
```
	
## Analysis
- `laklab_mouseloader.analysis_fns` contains functions to load and plot entire datasets
comprised of many experiments.

```python
import laklab_mouseloader.analysis_fns as lml_analysis
```

  - `lml_analysis.ephys_all = get_ephys_all()` parses a dataset for all
  experiments containing recordings from
  a particular region
  - `lml_analysis.plt_ephys_all_ordered(ephys_all)` plots a stimulus- or
  choice-aligned raster of the subset of ephys recordings from `get_ephys_all`.
  This can include ordering by time or by relative activity.
  
## Command line tools

### beh-check: Behavioral Performance Visualization

Quick visualization tool for daily behavioral performance in **Pavlovian (classical conditioning) experiments only**. Plots licking behavior across trials, separated by trial type.

**Usage:**
```bash
# Basic usage
beh-check /path/to/behavior/folder

# With noise flag (for experiments with noisy lick detector signal)
beh-check /path/to/behavior/folder -n
```

**Output:** PDF figure with trial-by-trial licking rasters, smoothed average licking rates (aligned to stimulus and reward), and anticipatory licking histogram, all separated by trial type (e.g., stimulus orientations, reward probabilities). Saved to parent directory as `{animal}_{date}_{folder}_behavior_summary.pdf`.
